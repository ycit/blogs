作用：

- 异步解耦
- 削峰填谷

### Kafka VS RocketMq

- kafka

  > Linkedin 开源的分布式发布-订阅消息系统，目前是 apache 顶级项目；由 Scala 语言开发
  >
  > 特点：基于 pull 模式来处理消息消费，追求高吞吐量，主要目的是用于日志收集和传输，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务；
  >
  > 
  >
  > 缺点：
  >
  > topic 过多会导致 kafka 吞吐量下降，磁盘成为瓶颈；
  >
  > kafka 的每个topic、每个 partition 都对应一个物理文件。当 topic 数量增加时，消息分散的落盘策略会导致磁盘 IO 竞争激烈成为瓶颈。而rocketMq 所有的消息是保存在同一个物理文件中，topic 和 分区数 对 RocketMq 也是逻辑概念上的划分，所以Topic数的增加对RocketMQ的性能不会造成太大的影响。
  >
  > **数据可靠性**：kafka 支持异步刷盘、同步复制、异步复制；异步刷盘有消息丢失的风险
  >
  > **性能**：单机写入大概在 百万条/秒，应为使用了异步刷盘，生产者批量发送；kafka 单机超过 64 个分区，会

- RabbitMq

  > Erlang 语言开发 ，基于 AMQP 协议实现，AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全

- RocketMQ

  > java 开发
  >
  > **数据可靠性**：RocketMQ 支持异步实时刷盘、同步刷盘、同步复制、异步复制；同步刷盘保证消息不会丢失
  >
  > **性能**：单机写入大概在 十万条/秒；RocketMQ 单机支持最高5万个队列，负载不会发生明显变化

### kafka消息丢失

#### 场景

1. 消息丢失 

   > 原因：
   >
   > 1. kafka 在发送消息前会将消息暂存到缓存中，当满足某个条件后才发发送消息，如果在发出消息之前，发生宕机，会导致消息丢失；
   > 2. auto.commit.enable=true，消费端自动提交offersets设置为true，当消费者拉到消息之后，还没有处理完 commit interval 提交间隔就到了，提交了offersets。这时consummer又挂了，重启后，从下一个offersets开始消费，之前的消息丢失了。
   > 3. 单 批 数 据 的 长 度 超 过 限 制 会 丢 失 数 据 ， 报kafka.common.Mess3.ageSizeTooLargeException异常
   > 4. 网络负载高、磁盘很忙，写入失败，又没有设置消息重试，导致数据丢失。
   > 5. 磁盘坏了已落盘数据丢失。
   >
   > 防止：
   >
   > 1. 设置auto.commit.enable=false，每次处理完手动提交。确保消息真的被消费并处理完成。
   > 2. 处理回调函数 producer.send(msg,callback)
   > 3. 设置重试机制
   > 4. 配置多个副本
   > 5. 生产者同步发送数据、同步刷盘（效率低下）

### 重复消费

1. 原因

   > 已消费，但是在提交时出现问题

2. 保证消费的幂等性

### 常用配置

```properties
#同步刷盘
request.required.acks=all  配置所有的partition 副本都收到消息了才返回提交消息成功；生产端
enable.auto.commit=false 设置为手动提交 ,消费端
retries=  出现问题比如网络抖动的重试次数；生产者端
unclean.leader.election.enable=false  数据缺失太多的 broker 不能成为 leader；broker 端
min.insync.replicas > 1 消息写入多少个副本才算提交；broker 端
replication.factor >= 3 消息分区的副本数; broker端
bootstrap.servers=  kafka 服务器配置
batch.size=   批量处理的数据量
linger.ms=  延迟时间
```



